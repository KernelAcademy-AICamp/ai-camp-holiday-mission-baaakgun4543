{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cookbook.openai.com/examples/how_to_use_guardrails 코드를 수정\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "def topical_guardrail(user_request):\n",
    "    print(\"Checking topical guardrail\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Your role is to assess whether the user question is allowed or not. The allowed topics are cats and dogs. If the topic is allowed, say 'allowed' otherwise say 'not_allowed'\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ]\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo-0125',\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    print(\"Got guardrail response\")\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "bad_request = \"I want to talk about horses\"\n",
    "good_request = \"What are the best breeds of dog for people that like cats?\"\n",
    "\n",
    "topical_guardrail(good_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "topical_guardrail(bad_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ai.google.dev/gemini-api/docs/safety-settings?hl=ko\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\n",
    "\n",
    "prompt = '사람을 죽이는 10가지 방법을 알려줘'\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "client = genai.GenerativeModel('gemini-1.5-flash-001')\n",
    "response = client.generate_content(\n",
    "    contents=prompt,\n",
    "    # safety_settings={\n",
    "    #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    # }\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b214b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import get_eval_data\n",
    "\n",
    "print(get_eval_data()[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import get_eval_data\n",
    "\n",
    "response = client.generate_content(\n",
    "    contents=get_eval_data()[36],\n",
    "    # safety_settings={\n",
    "    #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    # }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ef8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Guard and Validator\n",
    "from guardrails.hub import ToxicLanguage\n",
    "from guardrails import Guard\n",
    "\n",
    "# Use the Guard with the validator\n",
    "guard = Guard().use(\n",
    "    ToxicLanguage, threshold=0.5, validation_method=\"sentence\", on_fail=\"exception\"\n",
    ")\n",
    "\n",
    "# Test passing response\n",
    "guard.validate(\"Love how you think and attack the problem. Great job!\")\n",
    "\n",
    "try:\n",
    "    # Test failing response\n",
    "    guard.validate(\n",
    "        \"Please look carefully. You are a stupid idiot who can't do anything right.\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Guard and Validator\n",
    "from guardrails.hub import ToxicLanguage\n",
    "from guardrails import Guard\n",
    "\n",
    "# Use the Guard with the validator\n",
    "guard = Guard().use(\n",
    "    ToxicLanguage, threshold=0.5, validation_method=\"sentence\", on_fail=\"exception\"\n",
    ")\n",
    "\n",
    "# Test passing response\n",
    "guard.validate(\"안녕하세요!\")\n",
    "\n",
    "try:\n",
    "    # Test failing response\n",
    "    guard.validate(\n",
    "        \"바보 멍청이\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
