{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./res/rag_data.pkl', 'rb') as f:\n",
    "    rag_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rdk00nsryre",
   "source": "## ğŸ“‚ RAG ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n\nì´ì „ì— `rag_data.ipynb`ì—ì„œ ì €ì¥í•œ Pickle íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n\n- **`pickle.load()`**: ì €ì¥ëœ íŒŒì´ì¬ ê°ì²´ë¥¼ ë©”ëª¨ë¦¬ë¡œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°\n- **`'rb'` ëª¨ë“œ**: Read Binary (ë°”ì´ë„ˆë¦¬ ì½ê¸° ëª¨ë“œ)\n- **`rag_data`**: ì§ˆë¬¸, ì»¨í…ìŠ¤íŠ¸, ì •ë‹µ ë“±ì´ ë‹´ê¸´ ë”•ì…”ë„ˆë¦¬\n- **ëª©ì **: RAG ì‹œìŠ¤í…œì˜ íš¨ê³¼ë¥¼ ì‹¤í—˜í•˜ê¸° ìœ„í•œ ë°ì´í„° ì¤€ë¹„",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = rag_data['questions'][:10]\n",
    "contexts = rag_data['contexts'][:10]\n",
    "answers = rag_data['answers'][:10]\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8x9cxdl9hag",
   "source": "## ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n\nì‹¤í—˜ì„ ìœ„í•´ ì²˜ìŒ 10ê°œì˜ ë°ì´í„°ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n\n- **`questions`**: 10ê°œì˜ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\n- **`contexts`**: ê° ì§ˆë¬¸ë§ˆë‹¤ 3ê°œì”©ì˜ ì»¨í…ìŠ¤íŠ¸ (ì´ 10x3 êµ¬ì¡°)\n- **`answers`**: ê° ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µ 10ê°œ\n- **`[:10]`**: íŒŒì´ì¬ ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ ì²˜ìŒ 10ê°œë§Œ ì„ íƒ\n- **`len(questions)`**: ì¶”ì¶œí•œ ì§ˆë¬¸ ê°œìˆ˜ í™•ì¸ (ê²°ê³¼: 10)\n\n### ëª©ì \në¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•´ ì „ì²´ 200ê°œê°€ ì•„ë‹Œ ì¼ë¶€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from utils import call_openai, get_embeddings, cosine_similarity\n",
    "\n",
    "predictions = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    prompt = f\"\"\"You are an expert in Finance. Please answer to the question given below.\n",
    "    \n",
    "Question:\n",
    "{questions[i]}\n",
    "\"\"\"\n",
    "\n",
    "    prediction = call_openai(prompt, model='gpt-4o-2024-05-13')\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aj6odrpy06",
   "source": "## ğŸ¤– RAG ì—†ì´ GPT-4ë¡œ ì§ì ‘ ë‹µë³€ ìƒì„±\n\n**ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ì§€ ì•Šê³ ** GPT-4ì—ê²Œ ì§ˆë¬¸ë§Œ ë˜ì ¸ì„œ ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.\n\n### ë™ì‘ ê³¼ì •\n1. **ë°˜ë³µë¬¸**: 10ê°œ ì§ˆë¬¸ì„ í•˜ë‚˜ì”© ì²˜ë¦¬\n2. **í”„ë¡¬í”„íŠ¸ ì‘ì„±**: \n   - \"ë‹¹ì‹ ì€ ê¸ˆìœµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤\"\n   - ì§ˆë¬¸ë§Œ ì œê³µ (ì°¸ê³ í•  ë¬¸ì„œ ì—†ìŒ)\n3. **`call_openai()`**: GPT-4 ëª¨ë¸ì—ê²Œ ë‹µë³€ ìš”ì²­\n4. **ê²°ê³¼ ì €ì¥**: ìƒì„±ëœ ë‹µë³€ì„ `predictions` ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n\n### í•µì‹¬ í¬ì¸íŠ¸ âš ï¸\n- **ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ**: AIê°€ ìì‹ ì˜ í•™ìŠµ ë°ì´í„°ë§Œìœ¼ë¡œ ë‹µë³€\n- **í•œê³„**: ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë¬¸ì„œ ë‚´ìš©ì€ ëª¨ë¥¼ ìˆ˜ ìˆìŒ\n- **ë¹„êµ ê¸°ì¤€**: ë‚˜ì¤‘ì— RAGë¥¼ ì ìš©í•œ ê²°ê³¼ì™€ ë¹„êµí•  ê¸°ì¤€ì \n\n### ê²°ê³¼\n10ê°œ ì§ˆë¬¸ì— ëŒ€í•œ GPT-4ì˜ ì§ì ‘ ë‹µë³€ì´ `predictions`ì— ì €ì¥ë©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b33e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset \n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_correctness\n",
    "\n",
    "\n",
    "data_samples = {\n",
    "    'question': questions,\n",
    "    'answer': predictions,\n",
    "    'ground_truth': answers\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "score = evaluate(dataset, metrics=[answer_correctness])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hoo9y7h944",
   "source": "## ğŸ“‰ RAG ì—†ëŠ” ë‹µë³€ì˜ ì„±ëŠ¥ í‰ê°€\n\nì»¨í…ìŠ¤íŠ¸ ì—†ì´ ìƒì„±í•œ ë‹µë³€ì˜ ì •í™•ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.\n\n### í‰ê°€ ë°ì´í„° êµ¬ì„±\n- **`question`**: ì‚¬ìš©ì ì§ˆë¬¸ 10ê°œ\n- **`answer`**: GPT-4ê°€ ìƒì„±í•œ ë‹µë³€ (ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)\n- **`ground_truth`**: ì‹¤ì œ ì •ë‹µ\n\n### í‰ê°€ ë©”íŠ¸ë¦­\n- **`answer_correctness`**: ë‹µë³€ì´ ì •ë‹µê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ì¸¡ì •\n  - 0.0 ~ 1.0 ì‚¬ì´ ê°’\n  - 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •í™•í•œ ë‹µë³€\n  - **ì˜ë¯¸ì  ìœ ì‚¬ë„ + ì‚¬ì‹¤ ì •í™•ë„** ëª¨ë‘ ê³ ë ¤\n\n### ì´ ì ìˆ˜ì˜ ì˜ë¯¸\n- **ê¸°ì¤€ì (Baseline)**: RAGë¥¼ ì ìš©í•˜ì§€ ì•Šì€ ìƒíƒœì˜ ì„±ëŠ¥\n- **ë¹„êµ ëŒ€ìƒ**: ë‹¤ìŒ ë‹¨ê³„ì—ì„œ RAGë¥¼ ì ìš©í•œ í›„ì˜ ì„±ëŠ¥ê³¼ ë¹„êµ\n- **ì˜ˆìƒ ê²°ê³¼**: RAGë¥¼ ì ìš©í•˜ë©´ ì´ ì ìˆ˜ë³´ë‹¤ ë†’ì•„ì§ˆ ê²ƒìœ¼ë¡œ ê¸°ëŒ€",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jy3wsdh3u4",
   "source": "## ğŸ” ì²« ë²ˆì§¸ ì§ˆë¬¸ í™•ì¸\n\ní…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n\n- **ëª©ì **: ì–´ë–¤ ì§ˆë¬¸ì— ëŒ€í•´ í‰ê°€í•˜ê³  ìˆëŠ”ì§€ í™•ì¸\n- **ì˜ˆì‹œ**: \"ê¸€ë¡œë²Œ ì €ê¸ˆë¦¬ í˜„ìƒì´ ë¶€ê°ëœ ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n- **ë‹¤ìŒ ì…€ê³¼ ì—°ê²°**: ì´ ì§ˆë¬¸ì— ëŒ€í•œ GPT-4ì˜ ë‹µë³€ì„ í™•ì¸í•  ì˜ˆì •",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e715025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mo79dcb0ft",
   "source": "## ğŸ’¬ RAG ì—†ëŠ” ë‹µë³€ í™•ì¸\n\nì»¨í…ìŠ¤íŠ¸ ì—†ì´ GPT-4ê°€ ìƒì„±í•œ ì²« ë²ˆì§¸ ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n\n### íŠ¹ì§•\n- **ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ**: íŠ¹ì • ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì§€ ì•Šê³  ìƒì„±\n- **ì¼ë°˜ì ì¸ ë‹µë³€**: GPT-4ì˜ í•™ìŠµ ë°ì´í„°ì— ê¸°ë°˜í•œ ì¼ë°˜ì  ì§€ì‹\n- **í•œê³„ì **: \n  - êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ\n  - ìµœì‹  ì •ë³´ê°€ ë°˜ì˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\n  - íŠ¹ì • ë¬¸ì„œì˜ ì •í™•í•œ ë‚´ìš©ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n\n### ë¹„êµ ì¤€ë¹„\në‹¤ìŒ ë‹¨ê³„ì—ì„œ **RAGë¥¼ ì ìš©í•œ ë‹µë³€**ê³¼ ë¹„êµí•˜ì—¬ ì–¼ë§ˆë‚˜ ê°œì„ ë˜ëŠ”ì§€ í™•ì¸í•  ì˜ˆì •ì…ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import call_openai, get_embeddings, cosine_similarity\n",
    "\n",
    "\n",
    "def retrieve_context(question, contexts):\n",
    "    question_embedding = get_embeddings([question], model='text-embedding-3-large')[0]\n",
    "    context_embeddings = get_embeddings(contexts, model='text-embedding-3-large')\n",
    "\n",
    "    similarities = [cosine_similarity(question_embedding, context_embedding) for context_embedding in context_embeddings]\n",
    "\n",
    "    most_relevant_index = np.argmax(similarities)\n",
    "    return contexts[most_relevant_index]\n",
    "\n",
    "predictions = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    context = retrieve_context(questions[i], contexts[i])\n",
    "    prompt = f\"\"\"You are an expert in Finance. Please answer to the question given below. Use information given in Context appropriately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{questions[i]}\n",
    "\"\"\"\n",
    "    prediction = call_openai(prompt, model='gpt-4o-2024-05-13')\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "erj6c4ajld5",
   "source": "## ğŸ¯ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ë° ë‹µë³€ ìƒì„±\n\n**ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ì—¬** GPT-4ê°€ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n\n### `retrieve_context()` í•¨ìˆ˜ - RAGì˜ í•µì‹¬!\n```python\ndef retrieve_context(question, contexts):\n    # 1ë‹¨ê³„: ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n    question_embedding = get_embeddings([question], model='text-embedding-3-large')[0]\n    \n    # 2ë‹¨ê³„: ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n    context_embeddings = get_embeddings(contexts, model='text-embedding-3-large')\n    \n    # 3ë‹¨ê³„: ì§ˆë¬¸ê³¼ ê° ì»¨í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚°\n    similarities = [cosine_similarity(question_embedding, ce) for ce in context_embeddings]\n    \n    # 4ë‹¨ê³„: ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ì»¨í…ìŠ¤íŠ¸ ì°¾ê¸°\n    most_relevant_index = np.argmax(similarities)\n    \n    # 5ë‹¨ê³„: ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜\n    return contexts[most_relevant_index]\n```\n\n### ì „ì²´ RAG í”„ë¡œì„¸ìŠ¤\n1. **ê²€ìƒ‰(Retrieve)**: ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ ì°¾ê¸°\n2. **ì¦ê°•(Augment)**: ì°¾ì€ ì»¨í…ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€\n3. **ìƒì„±(Generate)**: ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ GPT-4ê°€ ë‹µë³€ ìƒì„±\n\n### í”„ë¡¬í”„íŠ¸ ì°¨ì´\n- **ì´ì „**: \"ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”\"\n- **í˜„ì¬**: \"Contextë¥¼ ì ì ˆíˆ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”\"\n\n### ê¸°ëŒ€ íš¨ê³¼ âœ¨\n- íŠ¹ì • ë¬¸ì„œì˜ ì •í™•í•œ ì •ë³´ í™œìš©\n- êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë‹µë³€\n- ì‚¬ì‹¤ ê¸°ë°˜ì˜ ì •í™•í•œ ë‹µë³€",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset \n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_correctness, context_relevancy, context_recall, context_precision\n",
    "\n",
    "\n",
    "data_samples = {\n",
    "    'question': questions,\n",
    "    'answer': predictions,\n",
    "    'ground_truth': answers\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "score = evaluate(dataset, metrics=[answer_correctness])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kpj82hnq9zo",
   "source": "## ğŸ“ˆ RAG ì ìš© í›„ ì„±ëŠ¥ í‰ê°€\n\nì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•œ í›„ì˜ ë‹µë³€ ì •í™•ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.\n\n### í‰ê°€ ë°ì´í„° êµ¬ì„±\n- **`question`**: ë™ì¼í•œ 10ê°œ ì§ˆë¬¸\n- **`answer`**: RAGë¥¼ ì ìš©í•˜ì—¬ ìƒì„±í•œ ë‹µë³€ (ì»¨í…ìŠ¤íŠ¸ ìˆìŒ)\n- **`ground_truth`**: ë™ì¼í•œ ì •ë‹µ\n\n### í‰ê°€ ë©”íŠ¸ë¦­\n- **`answer_correctness`**: ë‹µë³€ì˜ ì •í™•ë„ ì¸¡ì •\n\n### ë¹„êµ ë¶„ì„ ğŸ”\n| í•­ëª© | RAG ì—†ìŒ | RAG ì ìš© |\n|------|---------|---------|\n| ì»¨í…ìŠ¤íŠ¸ | âŒ ì—†ìŒ | âœ… ìˆìŒ |\n| ì •ë³´ ì¶œì²˜ | í•™ìŠµ ë°ì´í„° | íŠ¹ì • ë¬¸ì„œ |\n| ì •í™•ë„ | ë‚®ìŒ | **ë†’ìŒ** |\n\n### ê¸°ëŒ€ ê²°ê³¼\n- RAG ì—†ëŠ” ê²½ìš°ë³´ë‹¤ **ì ìˆ˜ê°€ ë†’ì•„ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒ**\n- ì»¨í…ìŠ¤íŠ¸ ì œê³µìœ¼ë¡œ ì¸í•œ ë‹µë³€ í’ˆì§ˆ í–¥ìƒ í™•ì¸\n- **RAGì˜ íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì¦ëª…**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pqxo6u1kred",
   "source": "## âœ¨ RAG ì ìš© ë‹µë³€ í™•ì¸\n\nì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ìƒì„±í•œ ì²« ë²ˆì§¸ ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n\n### íŠ¹ì§•\n- **ì»¨í…ìŠ¤íŠ¸ ìˆìŒ**: ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ìƒì„±\n- **êµ¬ì²´ì ì¸ ë‹µë³€**: íŠ¹ì • ë¬¸ì„œì˜ ì •ë³´ ê¸°ë°˜\n- **ê°œì„ ì **:\n  - ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë‚´ìš©\n  - ë¬¸ì„œì— ê¸°ë°˜í•œ ì •í™•í•œ ì •ë³´\n  - ì‚¬ì‹¤ ê´€ê³„ê°€ ëª…í™•í•¨\n\n### ë¹„êµí•´ë³¼ ì  ğŸ”\nì´ì „ ì…€(RAG ì—†ëŠ” ë‹µë³€)ê³¼ ë¹„êµí•˜ì—¬:\n- ë‹µë³€ì˜ êµ¬ì²´ì„±ì´ í–¥ìƒë˜ì—ˆëŠ”ê°€?\n- íŠ¹ì • ë¬¸ì„œì˜ ì •ë³´ê°€ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?\n- ì •í™•ë„ê°€ ê°œì„ ë˜ì—ˆëŠ”ê°€?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1mx2ljsp48",
   "source": "## âœ… ì‹¤ì œ ì •ë‹µ í™•ì¸\n\nì²« ë²ˆì§¸ ì§ˆë¬¸ì˜ ì‹¤ì œ ì •ë‹µ(ground truth)ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n\n### ëª©ì \n- **ìµœì¢… ë¹„êµ**: RAG ì—†ëŠ” ë‹µë³€ vs RAG ì ìš© ë‹µë³€ vs ì‹¤ì œ ì •ë‹µ\n- **í‰ê°€ ê¸°ì¤€**: RAGASê°€ ì´ ì •ë‹µì„ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¹€\n- **í’ˆì§ˆ í™•ì¸**: ìƒì„±ëœ ë‹µë³€ì´ ì‹¤ì œ ì •ë‹µê³¼ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ìœ¡ì•ˆìœ¼ë¡œ í™•ì¸\n\n### 3ê°€ì§€ ë‹µë³€ ë¹„êµ ìš”ì•½\n\n| êµ¬ë¶„ | íŠ¹ì§• | ì •í™•ë„ |\n|------|------|--------|\n| **RAG ì—†ìŒ** | ì¼ë°˜ì  ì§€ì‹ | ë‚®ìŒ |\n| **RAG ì ìš©** | ë¬¸ì„œ ê¸°ë°˜ | **ë†’ìŒ** â¬†ï¸ |\n| **ì‹¤ì œ ì •ë‹µ** | ê¸°ì¤€ê°’ | 100% |\n\n### í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ğŸ’¡\nRAGë¥¼ ì ìš©í•˜ë©´ ì‹¤ì œ ì •ë‹µì— ë” ê°€ê¹Œìš´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!",
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}